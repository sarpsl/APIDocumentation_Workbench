{
  "best_global_step": 5000,
  "best_metric": 0.0985492691397667,
  "best_model_checkpoint": "./fine_tuned_qa_model/checkpoint-5000",
  "epoch": 2.935995302407516,
  "eval_steps": 500,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.029359953024075163,
      "grad_norm": 5.335159778594971,
      "learning_rate": 2.35e-05,
      "loss": 2.8507,
      "step": 50
    },
    {
      "epoch": 0.058719906048150326,
      "grad_norm": 4.074305534362793,
      "learning_rate": 4.85e-05,
      "loss": 2.0147,
      "step": 100
    },
    {
      "epoch": 0.08807985907222549,
      "grad_norm": 4.147691249847412,
      "learning_rate": 4.9530844479936116e-05,
      "loss": 1.6015,
      "step": 150
    },
    {
      "epoch": 0.11743981209630065,
      "grad_norm": 3.997525691986084,
      "learning_rate": 4.903174286284688e-05,
      "loss": 1.4276,
      "step": 200
    },
    {
      "epoch": 0.14679976512037582,
      "grad_norm": 4.77960729598999,
      "learning_rate": 4.853264124575764e-05,
      "loss": 1.0925,
      "step": 250
    },
    {
      "epoch": 0.17615971814445097,
      "grad_norm": 5.982252597808838,
      "learning_rate": 4.80335396286684e-05,
      "loss": 1.0643,
      "step": 300
    },
    {
      "epoch": 0.20551967116852612,
      "grad_norm": 3.275054454803467,
      "learning_rate": 4.753443801157916e-05,
      "loss": 1.0647,
      "step": 350
    },
    {
      "epoch": 0.2348796241926013,
      "grad_norm": 3.7745065689086914,
      "learning_rate": 4.703533639448992e-05,
      "loss": 0.8266,
      "step": 400
    },
    {
      "epoch": 0.26423957721667646,
      "grad_norm": 5.754904747009277,
      "learning_rate": 4.653623477740068e-05,
      "loss": 0.6252,
      "step": 450
    },
    {
      "epoch": 0.29359953024075164,
      "grad_norm": 3.7121520042419434,
      "learning_rate": 4.603713316031144e-05,
      "loss": 0.6915,
      "step": 500
    },
    {
      "epoch": 0.29359953024075164,
      "eval_loss": 0.6656820774078369,
      "eval_runtime": 99.6259,
      "eval_samples_per_second": 3.804,
      "eval_steps_per_second": 1.907,
      "step": 500
    },
    {
      "epoch": 0.32295948326482676,
      "grad_norm": 2.733855724334717,
      "learning_rate": 4.553803154322221e-05,
      "loss": 0.6256,
      "step": 550
    },
    {
      "epoch": 0.35231943628890194,
      "grad_norm": 3.58581280708313,
      "learning_rate": 4.503892992613296e-05,
      "loss": 0.5291,
      "step": 600
    },
    {
      "epoch": 0.3816793893129771,
      "grad_norm": 3.2185449600219727,
      "learning_rate": 4.4539828309043725e-05,
      "loss": 0.5186,
      "step": 650
    },
    {
      "epoch": 0.41103934233705225,
      "grad_norm": 2.2958145141601562,
      "learning_rate": 4.404072669195448e-05,
      "loss": 0.4366,
      "step": 700
    },
    {
      "epoch": 0.44039929536112743,
      "grad_norm": 1.7866346836090088,
      "learning_rate": 4.354162507486524e-05,
      "loss": 0.3842,
      "step": 750
    },
    {
      "epoch": 0.4697592483852026,
      "grad_norm": 3.9448037147521973,
      "learning_rate": 4.3042523457776005e-05,
      "loss": 0.3625,
      "step": 800
    },
    {
      "epoch": 0.49911920140927774,
      "grad_norm": 2.1155052185058594,
      "learning_rate": 4.254342184068677e-05,
      "loss": 0.413,
      "step": 850
    },
    {
      "epoch": 0.5284791544333529,
      "grad_norm": 3.6407296657562256,
      "learning_rate": 4.204432022359753e-05,
      "loss": 0.4316,
      "step": 900
    },
    {
      "epoch": 0.557839107457428,
      "grad_norm": 8.078808784484863,
      "learning_rate": 4.1545218606508285e-05,
      "loss": 0.4922,
      "step": 950
    },
    {
      "epoch": 0.5871990604815033,
      "grad_norm": 1.4622325897216797,
      "learning_rate": 4.104611698941905e-05,
      "loss": 0.3468,
      "step": 1000
    },
    {
      "epoch": 0.5871990604815033,
      "eval_loss": 0.39554521441459656,
      "eval_runtime": 99.4307,
      "eval_samples_per_second": 3.812,
      "eval_steps_per_second": 1.911,
      "step": 1000
    },
    {
      "epoch": 0.6165590135055784,
      "grad_norm": 3.3553640842437744,
      "learning_rate": 4.054701537232981e-05,
      "loss": 0.3238,
      "step": 1050
    },
    {
      "epoch": 0.6459189665296535,
      "grad_norm": 5.11375617980957,
      "learning_rate": 4.0047913755240565e-05,
      "loss": 0.3175,
      "step": 1100
    },
    {
      "epoch": 0.6752789195537288,
      "grad_norm": 2.1732611656188965,
      "learning_rate": 3.9548812138151334e-05,
      "loss": 0.3243,
      "step": 1150
    },
    {
      "epoch": 0.7046388725778039,
      "grad_norm": 3.430793523788452,
      "learning_rate": 3.904971052106209e-05,
      "loss": 0.3054,
      "step": 1200
    },
    {
      "epoch": 0.733998825601879,
      "grad_norm": 2.6978976726531982,
      "learning_rate": 3.855060890397285e-05,
      "loss": 0.2666,
      "step": 1250
    },
    {
      "epoch": 0.7633587786259542,
      "grad_norm": 1.7915239334106445,
      "learning_rate": 3.805150728688361e-05,
      "loss": 0.2684,
      "step": 1300
    },
    {
      "epoch": 0.7927187316500294,
      "grad_norm": 1.3458788394927979,
      "learning_rate": 3.755240566979437e-05,
      "loss": 0.2766,
      "step": 1350
    },
    {
      "epoch": 0.8220786846741045,
      "grad_norm": 4.428122043609619,
      "learning_rate": 3.705330405270513e-05,
      "loss": 0.2385,
      "step": 1400
    },
    {
      "epoch": 0.8514386376981797,
      "grad_norm": 1.7530937194824219,
      "learning_rate": 3.6554202435615894e-05,
      "loss": 0.22,
      "step": 1450
    },
    {
      "epoch": 0.8807985907222549,
      "grad_norm": 3.6211941242218018,
      "learning_rate": 3.6055100818526656e-05,
      "loss": 0.2254,
      "step": 1500
    },
    {
      "epoch": 0.8807985907222549,
      "eval_loss": 0.24414919316768646,
      "eval_runtime": 99.4172,
      "eval_samples_per_second": 3.812,
      "eval_steps_per_second": 1.911,
      "step": 1500
    },
    {
      "epoch": 0.91015854374633,
      "grad_norm": 2.1100175380706787,
      "learning_rate": 3.555599920143741e-05,
      "loss": 0.2289,
      "step": 1550
    },
    {
      "epoch": 0.9395184967704052,
      "grad_norm": 0.6854368448257446,
      "learning_rate": 3.5056897584348174e-05,
      "loss": 0.1845,
      "step": 1600
    },
    {
      "epoch": 0.9688784497944803,
      "grad_norm": 0.8727842569351196,
      "learning_rate": 3.456777799960072e-05,
      "loss": 0.1898,
      "step": 1650
    },
    {
      "epoch": 0.9982384028185555,
      "grad_norm": 0.9832962155342102,
      "learning_rate": 3.406867638251148e-05,
      "loss": 0.2485,
      "step": 1700
    },
    {
      "epoch": 1.0275983558426307,
      "grad_norm": 2.2365081310272217,
      "learning_rate": 3.356957476542224e-05,
      "loss": 0.1351,
      "step": 1750
    },
    {
      "epoch": 1.0569583088667058,
      "grad_norm": 3.86167311668396,
      "learning_rate": 3.3070473148333e-05,
      "loss": 0.1588,
      "step": 1800
    },
    {
      "epoch": 1.086318261890781,
      "grad_norm": 2.2290616035461426,
      "learning_rate": 3.257137153124376e-05,
      "loss": 0.1222,
      "step": 1850
    },
    {
      "epoch": 1.115678214914856,
      "grad_norm": 3.343108892440796,
      "learning_rate": 3.2072269914154525e-05,
      "loss": 0.1434,
      "step": 1900
    },
    {
      "epoch": 1.1450381679389312,
      "grad_norm": 1.9103772640228271,
      "learning_rate": 3.157316829706529e-05,
      "loss": 0.1462,
      "step": 1950
    },
    {
      "epoch": 1.1743981209630066,
      "grad_norm": 0.6830190420150757,
      "learning_rate": 3.107406667997604e-05,
      "loss": 0.1334,
      "step": 2000
    },
    {
      "epoch": 1.1743981209630066,
      "eval_loss": 0.195567786693573,
      "eval_runtime": 99.8851,
      "eval_samples_per_second": 3.794,
      "eval_steps_per_second": 1.902,
      "step": 2000
    },
    {
      "epoch": 1.2037580739870817,
      "grad_norm": 0.7666006088256836,
      "learning_rate": 3.0574965062886805e-05,
      "loss": 0.1325,
      "step": 2050
    },
    {
      "epoch": 1.2331180270111568,
      "grad_norm": 2.5779929161071777,
      "learning_rate": 3.0075863445797563e-05,
      "loss": 0.1343,
      "step": 2100
    },
    {
      "epoch": 1.262477980035232,
      "grad_norm": 1.7547142505645752,
      "learning_rate": 2.9576761828708326e-05,
      "loss": 0.1502,
      "step": 2150
    },
    {
      "epoch": 1.291837933059307,
      "grad_norm": 2.839414358139038,
      "learning_rate": 2.9077660211619085e-05,
      "loss": 0.1377,
      "step": 2200
    },
    {
      "epoch": 1.3211978860833824,
      "grad_norm": 1.8235443830490112,
      "learning_rate": 2.8578558594529847e-05,
      "loss": 0.135,
      "step": 2250
    },
    {
      "epoch": 1.3505578391074575,
      "grad_norm": 2.892812490463257,
      "learning_rate": 2.807945697744061e-05,
      "loss": 0.1207,
      "step": 2300
    },
    {
      "epoch": 1.3799177921315327,
      "grad_norm": 1.8708487749099731,
      "learning_rate": 2.7580355360351368e-05,
      "loss": 0.1187,
      "step": 2350
    },
    {
      "epoch": 1.4092777451556078,
      "grad_norm": 1.0574512481689453,
      "learning_rate": 2.708125374326213e-05,
      "loss": 0.1276,
      "step": 2400
    },
    {
      "epoch": 1.438637698179683,
      "grad_norm": 1.4281049966812134,
      "learning_rate": 2.658215212617289e-05,
      "loss": 0.1177,
      "step": 2450
    },
    {
      "epoch": 1.467997651203758,
      "grad_norm": 1.4260363578796387,
      "learning_rate": 2.608305050908365e-05,
      "loss": 0.1373,
      "step": 2500
    },
    {
      "epoch": 1.467997651203758,
      "eval_loss": 0.15074288845062256,
      "eval_runtime": 99.419,
      "eval_samples_per_second": 3.812,
      "eval_steps_per_second": 1.911,
      "step": 2500
    },
    {
      "epoch": 1.4973576042278331,
      "grad_norm": 0.8222061991691589,
      "learning_rate": 2.5583948891994414e-05,
      "loss": 0.1346,
      "step": 2550
    },
    {
      "epoch": 1.5267175572519083,
      "grad_norm": 1.8076235055923462,
      "learning_rate": 2.5084847274905173e-05,
      "loss": 0.1118,
      "step": 2600
    },
    {
      "epoch": 1.5560775102759834,
      "grad_norm": 2.5380783081054688,
      "learning_rate": 2.458574565781593e-05,
      "loss": 0.1156,
      "step": 2650
    },
    {
      "epoch": 1.5854374633000587,
      "grad_norm": 0.7117288112640381,
      "learning_rate": 2.4086644040726694e-05,
      "loss": 0.1086,
      "step": 2700
    },
    {
      "epoch": 1.6147974163241339,
      "grad_norm": 0.8435234427452087,
      "learning_rate": 2.3587542423637453e-05,
      "loss": 0.1072,
      "step": 2750
    },
    {
      "epoch": 1.644157369348209,
      "grad_norm": 2.0399727821350098,
      "learning_rate": 2.3088440806548215e-05,
      "loss": 0.1089,
      "step": 2800
    },
    {
      "epoch": 1.6735173223722843,
      "grad_norm": 0.7948246002197266,
      "learning_rate": 2.2589339189458974e-05,
      "loss": 0.116,
      "step": 2850
    },
    {
      "epoch": 1.7028772753963595,
      "grad_norm": 0.7406439781188965,
      "learning_rate": 2.2090237572369736e-05,
      "loss": 0.0959,
      "step": 2900
    },
    {
      "epoch": 1.7322372284204346,
      "grad_norm": 1.2824957370758057,
      "learning_rate": 2.1591135955280495e-05,
      "loss": 0.111,
      "step": 2950
    },
    {
      "epoch": 1.7615971814445097,
      "grad_norm": 1.1270173788070679,
      "learning_rate": 2.1092034338191257e-05,
      "loss": 0.1016,
      "step": 3000
    },
    {
      "epoch": 1.7615971814445097,
      "eval_loss": 0.13137027621269226,
      "eval_runtime": 99.7826,
      "eval_samples_per_second": 3.798,
      "eval_steps_per_second": 1.904,
      "step": 3000
    },
    {
      "epoch": 1.7909571344685848,
      "grad_norm": 1.2807399034500122,
      "learning_rate": 2.059293272110202e-05,
      "loss": 0.099,
      "step": 3050
    },
    {
      "epoch": 1.82031708749266,
      "grad_norm": 1.165258526802063,
      "learning_rate": 2.0093831104012778e-05,
      "loss": 0.1055,
      "step": 3100
    },
    {
      "epoch": 1.849677040516735,
      "grad_norm": 2.893524169921875,
      "learning_rate": 1.9594729486923537e-05,
      "loss": 0.1104,
      "step": 3150
    },
    {
      "epoch": 1.8790369935408102,
      "grad_norm": 0.9954448938369751,
      "learning_rate": 1.90956278698343e-05,
      "loss": 0.1057,
      "step": 3200
    },
    {
      "epoch": 1.9083969465648853,
      "grad_norm": 0.801239550113678,
      "learning_rate": 1.859652625274506e-05,
      "loss": 0.1021,
      "step": 3250
    },
    {
      "epoch": 1.9377568995889607,
      "grad_norm": 0.9199338555335999,
      "learning_rate": 1.809742463565582e-05,
      "loss": 0.1075,
      "step": 3300
    },
    {
      "epoch": 1.9671168526130358,
      "grad_norm": 0.7577160596847534,
      "learning_rate": 1.7598323018566583e-05,
      "loss": 0.1059,
      "step": 3350
    },
    {
      "epoch": 1.996476805637111,
      "grad_norm": 0.7140074968338013,
      "learning_rate": 1.7099221401477342e-05,
      "loss": 0.0986,
      "step": 3400
    },
    {
      "epoch": 2.0258367586611863,
      "grad_norm": 0.6192277073860168,
      "learning_rate": 1.66001197843881e-05,
      "loss": 0.0917,
      "step": 3450
    },
    {
      "epoch": 2.0551967116852614,
      "grad_norm": 0.8350518941879272,
      "learning_rate": 1.6101018167298863e-05,
      "loss": 0.0929,
      "step": 3500
    },
    {
      "epoch": 2.0551967116852614,
      "eval_loss": 0.11854736506938934,
      "eval_runtime": 100.7855,
      "eval_samples_per_second": 3.76,
      "eval_steps_per_second": 1.885,
      "step": 3500
    },
    {
      "epoch": 2.0845566647093365,
      "grad_norm": 1.004024863243103,
      "learning_rate": 1.5601916550209622e-05,
      "loss": 0.0945,
      "step": 3550
    },
    {
      "epoch": 2.1139166177334117,
      "grad_norm": 1.4708596467971802,
      "learning_rate": 1.5102814933120386e-05,
      "loss": 0.0878,
      "step": 3600
    },
    {
      "epoch": 2.143276570757487,
      "grad_norm": 0.9223664402961731,
      "learning_rate": 1.4603713316031145e-05,
      "loss": 0.0873,
      "step": 3650
    },
    {
      "epoch": 2.172636523781562,
      "grad_norm": 1.0717551708221436,
      "learning_rate": 1.4104611698941905e-05,
      "loss": 0.0907,
      "step": 3700
    },
    {
      "epoch": 2.201996476805637,
      "grad_norm": 0.7011281251907349,
      "learning_rate": 1.3605510081852666e-05,
      "loss": 0.0893,
      "step": 3750
    },
    {
      "epoch": 2.231356429829712,
      "grad_norm": 1.1001513004302979,
      "learning_rate": 1.3106408464763426e-05,
      "loss": 0.0934,
      "step": 3800
    },
    {
      "epoch": 2.2607163828537873,
      "grad_norm": 0.9863036870956421,
      "learning_rate": 1.2607306847674185e-05,
      "loss": 0.0943,
      "step": 3850
    },
    {
      "epoch": 2.2900763358778624,
      "grad_norm": 1.4649816751480103,
      "learning_rate": 1.2108205230584947e-05,
      "loss": 0.0859,
      "step": 3900
    },
    {
      "epoch": 2.3194362889019375,
      "grad_norm": 0.7703503370285034,
      "learning_rate": 1.1609103613495708e-05,
      "loss": 0.0875,
      "step": 3950
    },
    {
      "epoch": 2.348796241926013,
      "grad_norm": 1.4384642839431763,
      "learning_rate": 1.1110001996406469e-05,
      "loss": 0.0857,
      "step": 4000
    },
    {
      "epoch": 2.348796241926013,
      "eval_loss": 0.11121910065412521,
      "eval_runtime": 100.373,
      "eval_samples_per_second": 3.776,
      "eval_steps_per_second": 1.893,
      "step": 4000
    },
    {
      "epoch": 2.3781561949500882,
      "grad_norm": 1.057930588722229,
      "learning_rate": 1.061090037931723e-05,
      "loss": 0.0917,
      "step": 4050
    },
    {
      "epoch": 2.4075161479741634,
      "grad_norm": 0.6796786189079285,
      "learning_rate": 1.011179876222799e-05,
      "loss": 0.0856,
      "step": 4100
    },
    {
      "epoch": 2.4368761009982385,
      "grad_norm": 0.9360226392745972,
      "learning_rate": 9.61269714513875e-06,
      "loss": 0.084,
      "step": 4150
    },
    {
      "epoch": 2.4662360540223136,
      "grad_norm": 0.87420254945755,
      "learning_rate": 9.113595528049511e-06,
      "loss": 0.0867,
      "step": 4200
    },
    {
      "epoch": 2.4955960070463887,
      "grad_norm": 1.0178849697113037,
      "learning_rate": 8.614493910960273e-06,
      "loss": 0.0884,
      "step": 4250
    },
    {
      "epoch": 2.524955960070464,
      "grad_norm": 1.5103204250335693,
      "learning_rate": 8.115392293871032e-06,
      "loss": 0.0866,
      "step": 4300
    },
    {
      "epoch": 2.554315913094539,
      "grad_norm": 0.7749834656715393,
      "learning_rate": 7.616290676781793e-06,
      "loss": 0.0893,
      "step": 4350
    },
    {
      "epoch": 2.583675866118614,
      "grad_norm": 0.8294752240180969,
      "learning_rate": 7.117189059692554e-06,
      "loss": 0.0864,
      "step": 4400
    },
    {
      "epoch": 2.6130358191426892,
      "grad_norm": 1.0792129039764404,
      "learning_rate": 6.618087442603315e-06,
      "loss": 0.0827,
      "step": 4450
    },
    {
      "epoch": 2.642395772166765,
      "grad_norm": 0.9897803664207458,
      "learning_rate": 6.118985825514075e-06,
      "loss": 0.0828,
      "step": 4500
    },
    {
      "epoch": 2.642395772166765,
      "eval_loss": 0.10535439848899841,
      "eval_runtime": 99.6274,
      "eval_samples_per_second": 3.804,
      "eval_steps_per_second": 1.907,
      "step": 4500
    },
    {
      "epoch": 2.67175572519084,
      "grad_norm": 0.9364451169967651,
      "learning_rate": 5.619884208424835e-06,
      "loss": 0.0895,
      "step": 4550
    },
    {
      "epoch": 2.701115678214915,
      "grad_norm": 0.9390701651573181,
      "learning_rate": 5.120782591335596e-06,
      "loss": 0.0842,
      "step": 4600
    },
    {
      "epoch": 2.73047563123899,
      "grad_norm": 0.8120003938674927,
      "learning_rate": 4.621680974246357e-06,
      "loss": 0.0915,
      "step": 4650
    },
    {
      "epoch": 2.7598355842630653,
      "grad_norm": 1.1164799928665161,
      "learning_rate": 4.1225793571571175e-06,
      "loss": 0.0821,
      "step": 4700
    },
    {
      "epoch": 2.7891955372871404,
      "grad_norm": 0.9207736253738403,
      "learning_rate": 3.623477740067878e-06,
      "loss": 0.0788,
      "step": 4750
    },
    {
      "epoch": 2.8185554903112156,
      "grad_norm": 0.7433459758758545,
      "learning_rate": 3.1243761229786387e-06,
      "loss": 0.081,
      "step": 4800
    },
    {
      "epoch": 2.8479154433352907,
      "grad_norm": 0.6915205717086792,
      "learning_rate": 2.6252745058893992e-06,
      "loss": 0.0829,
      "step": 4850
    },
    {
      "epoch": 2.877275396359366,
      "grad_norm": 0.7034900784492493,
      "learning_rate": 2.12617288880016e-06,
      "loss": 0.0794,
      "step": 4900
    },
    {
      "epoch": 2.906635349383441,
      "grad_norm": 0.6383269429206848,
      "learning_rate": 1.6270712717109206e-06,
      "loss": 0.0814,
      "step": 4950
    },
    {
      "epoch": 2.935995302407516,
      "grad_norm": 1.0319832563400269,
      "learning_rate": 1.127969654621681e-06,
      "loss": 0.0843,
      "step": 5000
    },
    {
      "epoch": 2.935995302407516,
      "eval_loss": 0.0985492691397667,
      "eval_runtime": 99.8996,
      "eval_samples_per_second": 3.794,
      "eval_steps_per_second": 1.902,
      "step": 5000
    }
  ],
  "logging_steps": 50,
  "max_steps": 5109,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9663660225331200.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
